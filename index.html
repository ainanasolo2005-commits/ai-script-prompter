<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Script Assistant (Manual Read)</title>
    <style>
        body { font-family: sans-serif; background: #000; color: #fff; margin: 0; overflow: hidden; }
        .video-bg { position: fixed; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; z-index: -1; filter: brightness(0.4); }
        .container { display: flex; flex-direction: column; height: 100vh; padding: 20px; box-sizing: border-box; }
        .status { background: rgba(255, 0, 0, 0.7); padding: 5px 15px; border-radius: 20px; font-size: 12px; width: fit-content; margin-bottom: 10px; }
        .script-box { flex: 1; display: flex; align-items: center; justify-content: center; text-align: center; }
        #aiScript { font-size: 28px; font-weight: bold; line-height: 1.5; color: #00FFCC; text-shadow: 2px 2px 4px #000; }
        .user-listen { font-size: 14px; color: #aaa; margin-top: 10px; font-style: italic; }
    </style>
</head>
<body>

<video id="webcam" class="video-bg" autoplay muted playsinline></video>

<div class="container">
    <div class="status">LIVE ‚óè RECORDING</div>
    <div class="script-box">
        <div id="aiScript">Waiting for the other person to speak...</div>
    </div>
    <div id="userListen" class="user-listen">Listening...</div>
</div>

<script>
    const scriptBox = document.getElementById('aiScript');
    const userListen = document.getElementById('userListen');

    // 1. START CAMERA (Z-Index Background)
    navigator.mediaDevices.getUserMedia({ video: true, audio: true }).then(stream => {
        document.getElementById('webcam').srcObject = stream;
        startListening();
    }).catch(err => scriptBox.innerText = "Error: Camera access required.");

    // 2. DETECT SPEECH AND SHOW TEXT (NO VOICE OUTPUT)
    function startListening() {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (!SpeechRecognition) return;

        const recognition = new SpeechRecognition();
        recognition.lang = 'en-US'; // Ovay ho 'mg-MG' raha teny malagasy no andrasanao
        recognition.continuous = true;

        recognition.onresult = (event) => {
            const transcript = event.results[event.results.length - 1][0].transcript;
            userListen.innerText = "They said: " + transcript;

            // AI Suggestion (For you to read)
            setTimeout(() => {
                const response = "That is an excellent point. I believe that integrating these solutions will maximize our overall efficiency.";
                scriptBox.innerText = response; // Ity no vakianao mafy
            }, 800);
        };

        recognition.onend = () => recognition.start();
        recognition.start();
    }
</script>

</body>
  </html>
